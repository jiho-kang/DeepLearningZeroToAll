{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc3a718e",
   "metadata": {},
   "source": [
    "# 모두를 위한 딥러닝 tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fabf611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hello Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f79c549d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello,Tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant(\"Hello,Tensorflow!\")\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c12fb86",
   "metadata": {},
   "source": [
    "# 01) Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0fa7c4",
   "metadata": {},
   "source": [
    "(1) Build graph(tensors) using TensorFlow operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5916b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32) #넣을내용,데이터형식\n",
    "node2 = tf.constant(4.0) #also tf.float32 implicitly\n",
    "node3 = tf.add(node1,node2) #node3 = node1 + node2도 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b4e29d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1: Tensor(\"Const_3:0\", shape=(), dtype=float32) node2: Tensor(\"Const_3:0\", shape=(), dtype=float32)\n",
      "node3: Tensor(\"Add:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"node1:\", node2, \"node2:\", node2)\n",
    "print(\"node3:\", node3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de95278",
   "metadata": {},
   "source": [
    "(2) feed data and run graph (operation)\n",
    "    sess.run(op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e5ed6",
   "metadata": {},
   "source": [
    "(3) update variables in the graph\n",
    "    (and return values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e474e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run([node1,node2]):  [3.0, 4.0]\n",
      "sess.run(node3):  7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"sess.run([node1,node2]): \",sess.run([node1,node2]))\n",
    "print(\"sess.run(node3): \",sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348df16d",
   "metadata": {},
   "source": [
    "### Placeholder (like input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c46927",
   "metadata": {},
   "source": [
    "placeholder로 미지수로 남기고, feed_dict로 넣어줌. n개 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c100ac71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a+b #tf.add(a,b)도 가능\n",
    "\n",
    "print(sess.run(adder_node, feed_dict={a:3,b:4.5}))\n",
    "print(sess.run(adder_node, feed_dict={a:[1,3], b:[2,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c28fddf",
   "metadata": {},
   "source": [
    "### Tensor Ranks, Shpaes and Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6dbc4a",
   "metadata": {},
   "source": [
    "Rank / Mateh entity / Python example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384448f6",
   "metadata": {},
   "source": [
    "    0 / Scalar(magnitude only) / s = 483\n",
    "    1 / Vector(magnitude and directioni) / v = [1.2, 3.3, 4.3]\n",
    "    2 / Matrix(table of numbers) / m = [[1,2], [5,6], [7,3]]\n",
    "    3 / 3-Tensor(cube of numbers) t = [[[2],[3],[4]],[[5],[6],[7]],[[8],[9],[10]]]\n",
    "    n / n-Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7009821",
   "metadata": {},
   "source": [
    "# 02) Linear regression 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd8f2b",
   "metadata": {},
   "source": [
    "### (1) Build graph using TF operations\n",
    "H(x) = Wx+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b016507",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3]\n",
    "y = [1,2,3]\n",
    "\n",
    "#tt.Variable = TF가 학습하는 과정에서 변경시키는 v이다.\n",
    "w = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "#our hypothesis Wx+b\n",
    "hypothesis = w*x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d04a452",
   "metadata": {},
   "source": [
    "cost(W,b) = 1/m (시그마 i=1~m : (H(xi)-yi)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb68297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.reduce_mean: 평균 값을 구해줌\n",
    "#tf.square: 제곱\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14097d66",
   "metadata": {},
   "source": [
    "GradientDescent (경사하강법)로 cost 최소값 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a800ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer =  tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c26cb86",
   "metadata": {},
   "source": [
    "### (2),(3) Run/Update graph and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0c0473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 None 15.762543 [-1.9815823] [2.8269267]\n",
      "100 None 1.0607485 [-0.19620547] [2.719229]\n",
      "200 None 0.6523307 [0.06194156] [2.132427]\n",
      "300 None 0.401165 [0.26437336] [1.6722523]\n",
      "400 None 0.24670522 [0.4231205] [1.3113828]\n",
      "500 None 0.15171678 [0.5476103] [1.0283883]\n",
      "600 None 0.093301594 [0.6452353] [0.8064636]\n",
      "700 None 0.057377815 [0.72179306] [0.6324298]\n",
      "800 None 0.035285737 [0.7818297] [0.4959523]\n",
      "900 None 0.021699736 [0.8289106] [0.38892657]\n",
      "1000 None 0.01334473 [0.8658314] [0.3049967]\n",
      "1100 None 0.00820664 [0.8947848] [0.23917891]\n",
      "1200 None 0.005046841 [0.9174901] [0.18756437]\n",
      "1300 None 0.0031036653 [0.9352957] [0.14708824]\n",
      "1400 None 0.0019086679 [0.9492586] [0.11534683]\n",
      "1500 None 0.0011737797 [0.96020865] [0.09045516]\n",
      "1600 None 0.0007218362 [0.9687956] [0.07093499]\n",
      "1700 None 0.0004439084 [0.9755295] [0.05562723]\n",
      "1800 None 0.00027299262 [0.9808102] [0.04362299]\n",
      "1900 None 0.00016788131 [0.9849513] [0.03420916]\n",
      "2000 None 0.00010324144 [0.9881988] [0.02682685]\n"
     ]
    }
   ],
   "source": [
    "sess =tf.Session()\n",
    "#tf.variable을 사용할 경우 run전에 tf.global_variables_initializer()를 사용해야함\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 100 == 0:\n",
    "        print(step, sess.run(cost), sess.run(w), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b050d",
   "metadata": {},
   "source": [
    "### Full code with placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a738f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.0342264 [0.7811154] [0.20755665]\n",
      "200 0.027220666 [1.1369014] [0.6974932]\n",
      "400 0.008203988 [1.0751572] [0.87902856]\n",
      "600 0.0024725902 [1.0412605] [0.9786892]\n",
      "800 0.00074520375 [1.0226514] [1.0334018]\n",
      "1000 0.00022459036 [1.0124351] [1.0634389]\n",
      "1200 6.769014e-05 [1.0068269] [1.0799282]\n",
      "1400 2.0401305e-05 [1.0037479] [1.0889806]\n",
      "1600 6.148981e-06 [1.0020576] [1.0939503]\n",
      "1800 1.853588e-06 [1.0011296] [1.0966785]\n",
      "2000 5.5907356e-07 [1.0006204] [1.0981758]\n",
      "[6.1012774]\n",
      "[3.5997267]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "w = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "x = tf.placeholder(tf.float32, shape = [None])\n",
    "y = tf.placeholder(tf.float32, shape = [None])\n",
    "\n",
    "hy = w*x+b\n",
    "cost = tf.reduce_mean(tf.square(hy-y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, w_val, b_val, _ = sess.run([cost, w, b, train], feed_dict={x:[1,2,3,4], y:[2.1,3.1,4.1,5.1]})\n",
    "    if step %200==0:\n",
    "        print(step,cost_val,w_val,b_val)\n",
    "        \n",
    "print(sess.run(hy, feed_dict={x: [5]}))\n",
    "print(sess.run(hy, feed_dict={x: [2.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936b7a0e",
   "metadata": {},
   "source": [
    "# 03) Linear Regression의 cost 최소화 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d759c0",
   "metadata": {},
   "source": [
    "### cost함수 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e33cffd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqs0lEQVR4nO3deXhV5bn+8e+ThCQQEiBkIEDClBBkDDOIoIAoKgpaW6SKaI/FttLa1tbaudVfT2l7jlZrrVJFUZHWAQriiIgMgkCYZwIkhDBlAAJJyLif3x/Z9lBl2CHZe+3h+VxXrrXXJsm6mW4W71rrfUVVMcYYE3jCnA5gjDHm8liBG2NMgLICN8aYAGUFbowxAcoK3BhjAlSELw+WkJCgnTt39uUhjTEm4G3YsKFYVRO/+L5PC7xz585kZ2f78pDGGBPwROTg+d63IRRjjAlQVuDGGBOgrMCNMSZAWYEbY0yAsgI3xpgAZQVujDEBygrcGGMCVEAU+MqcIp75ZJ/TMYwxxq8ERIGvyinm8Q/3Unim0ukoxhjjNwKiwCcPTqXWpby5ocDpKMYY4zcCosC7JrZkaJd4/rn+EC6XrSBkjDEQIAUOMGVIGgdLKlhzoMTpKMYY4xcCpsDH925Hq+bNmLcu3+koxhjjFwKmwKObhXNr/w58uOM4J8qrnY5jjDGOC5gCh/phlOo6F/M32sVMY4wJqALPbBdL/7TWzFuXj6pdzDTGhLaAKnCAKYPT2F9UTvbBk05HMcYYR12ywEUkU0Q2n/NxWkS+LyLxIrJERHLc2za+CDyhXwotoyLsYqYxJiAUnq5kwl9WsuHgiSb/3pcscFXdo6pZqpoFDAQqgAXAI8BSVc0Alrr3va5FZAQTs9rzztajlFbU+OKQxhhz2V7PPsT2w6eJj4lq8u/d0CGUscB+VT0ITATmuN+fA0xqwlwXdefQTlTVunjLLmYaY/xYnUuZt+4QI9Lb0iUhpsm/f0ML/A5gnvt1sqoeBXBvk5oy2MX0bB9HVmpr5q49aBczjTF+a/neQg6fOsudQzt55ft7XOAiEgncArzRkAOIyHQRyRaR7KKioobmu6A7h9ZfzFyb2/TjSsYY0xReW5tPYmwU43ome+X7N+QM/AZgo6oed+8fF5EUAPe28HxfpKqzVHWQqg5KTExsXNpzTOjbnrjoCF5baxczjTH+5/Cps3y8u5DJg1JpFu6dG/4a8l2n8H/DJwCLgGnu19OAhU0VyhPNI8O5bUBH3tt+lOKyKl8e2hhjLumf6/JR4I4hqV47hkcFLiItgHHA/HPengmME5Ec94/NbPp4F3fn0DRq6myaWWOMf6mpc/GP9Ye4pnsiHdu08NpxPCpwVa1Q1baqWnrOeyWqOlZVM9xbnw9GZyTHMqRLPPPW5ds0s8YYv7F0VyGFZ6q8dvHycwH3JOYX3Tm0fprZT/cXOx3FGGMAmLv2ICmtorkms+mu+51PwBf4+N7tiI+J5NXPDjodxRhjOFhSzsqcYiYPTiXCSxcvPxfwBR4VEc7XBqXy0a5CjpaedTqOMSbEvfrZQSLChClD0rx+rIAvcKgfRnGpMs9uKTTGOKiypo7Xswu4vlc7kuOivX68oCjw1PgWjMlM4rV1h6iudTkdxxgTot7ecoTSszVMHe7di5efC4oCB7hreCeKy6r4YMcxp6MYY0LUK58dJCOpfhF2XwiaAr86I5G0+Ba8ssYuZhpjfG/LoVNsLShl6vBOiIhPjhk0BR4WJtw1LI11eSfYfey003GMMSHmlc8OEhNZv3avrwRNgQN8dWAqURFhdhZujPGpk+XVvL3lCLcO6EBsdDOfHTeoCrxNTCQ392vPgk2HOVNpiz0YY3zjjQ2HqKp1MXVYZ58eN6gKHGDqsE5UVNcxf+Nhp6MYY0JAnUt59bN8hnSJJ7NdrE+PHXQF3i+1Nf1SWzNnTZ7Nj2KM8bpP9hSSf6KCu3106+C5gq7AAe65shMHispZtc/mRzHGeNdLq/NoFxfN9b3a+fzYQVngN/ZJIaFlFC+tznM6ijEmiO0rLGNlTjFTh3fy2qINFxOUBR4VEc7Xh6axbE8hB0vKnY5jjAlSL6/JIzIijDsGe2/RhosJygKH+vlRwkV42W4pNMZ4wenKGt7cUMDNfdvTtmWUIxmCtsCT46K5sU8Kr68/RHlVrdNxjDFB5s3sAiqq67jnys6OZQjaAgeYdmVnzlTVMn+T3VJojGk6Lpfy8po8BnZqQ5+OrRzL4emamK1F5E0R2S0iu0RkuIjEi8gSEclxb9t4O2xDDUhrTZ8OrXh5dR6qdkuhMaZpLN9bRF5JBdMcPPsGz8/AnwTeV9UeQD9gF/AIsFRVM4Cl7n2/IiLcc2VncgrL+HRfidNxjDFB4sXVeSTHRXFDb9/fOniuSxa4iMQBo4AXAFS1WlVPAROBOe5PmwNM8k7ExpnQL4WElpHM/jTX6SjGmCCwr/AMK/YWcddQZ24dPJcnR+8KFAEvisgmEXleRGKAZFU9CuDeJp3vi0Vkuohki0h2UVFRkwX3VFREOHcN68THuws5UFTm8+MbY4LL7E/ziIoI4+tDvb9k2qV4UuARwADgb6raHyinAcMlqjpLVQep6qDERO+u0Hwhdw7tRGR4GC9+mufI8Y0xweFkeTXzNxZwa/8Ojt06eC5PCrwAKFDVte79N6kv9OMikgLg3hZ6J2LjJcZGMTGrPW9uKKC0wmYpNMZcntfW5VNZ4+IbV3VxOgrgQYGr6jHgkIhkut8aC+wEFgHT3O9NAxZ6JWETuXdEF87W1DFvvS18bIxpuJo6Fy+vyWNkRgLdk3076+CFeDoC/11grohsBbKA/wZmAuNEJAcY5973Wz3bx3Flt7bMWZ1HTZ0tfGyMaZh3tx3l+Okqvzn7Bg8LXFU3u8ex+6rqJFU9qaolqjpWVTPc2xPeDttY3xjRhaOllby/3RY+NsZ4TlWZvSqXrokxXJ3hzLW88wnqJzG/aEyPJDq3bWG3FBpjGmRj/km2FJRy74guhIX5ZsFiT4RUgYeFCfeO6MKm/FNsOHjS6TjGmADx/MpcWjVvxlcG+G7BYk+EVIED3D6wI3HRETy/8oDTUYwxAeBgSTkf7DjGnUPTaBEZ4XSc/xByBR4TFcFdwzrx/o5jNle4MeaSZq/KJTxMHJ118EJCrsAB7rmyMxFhwuxVNhZujLmwUxXVvJ5dwKSsDiTFRTsd50tCssCT4qKZmNWB17MLOFle7XQcY4yfmrs2n7M1ddw3sqvTUc4rJAsc4Jsju3K2po65a23FHmPMl1XV1vHip3lc3T2RzHb+8eDOF4VsgWe2i+Xq7om8tPogVbV1TscxxviZhZuOUFxWxfRR/nn2DSFc4FB/Fl5cVsXCTUecjmKM8SMulzJr5QGuSKl/gttfhXSBj0hvyxUpcfx95QFcLluxxxhTb/neIvYVljF9VBdE/OfBnS8K6QIXEaaP6kJOYRnL9vjtZIrGGB97dvl+UlpFM6Fve6ejXFRIFzjAhL7t6dC6Oc8u3+90FGOMH9iUf5K1uSf4r6u6OL7izqX4dzofaBYexn0ju7A+7yTZeX4/H5cxxsueXb6fVs2bMWWI8yvuXErIFzjA5MGptGnRzM7CjQlx+wrL+HDnce4e3omYKP96bP58rMCBFpERTLuyMx/tKmTv8TNOxzHGOGTWiv1EhocxzQ8fmz8fK3C3acM707xZOM8tt0mujAlFx0orWbDpMF8blEqCH6x36QkrcLc2MZFMHpzKws2HOXzqrNNxjDE+NvvTXFyKXz+480UeFbiI5InINhHZLCLZ7vfiRWSJiOS4t228G9X77htZv1TSCyttkitjQknp2RpeW5vPTX1SSI1v4XQcjzXkDHy0qmap6iD3/iPAUlXNAJa69wNaxzYtuKVfe+aty+eETXJlTMh4ZU0eZVW13H914Jx9Q+OGUCYCc9yv5wCTGp3GD3z7mm6cranjJVt2zZiQUFFdywurchmdmUiv9q2cjtMgnha4Ah+KyAYRme5+L1lVjwK4t0neCOhrGcmxjO/VjpdW53GmssbpOMYYL5u37hAnK2qYMSbd6SgN5mmBj1DVAcANwAMiMsrTA4jIdBHJFpHsoqKiywrpaw+MTud0ZS2vfGZTzRoTzKpq65i1Yj9Du8QzsFO803EazKMCV9Uj7m0hsAAYAhwXkRQA9/a8k4mo6ixVHaSqgxITE5smtZf16diKUd0TeWFlLmerbapZY4LVWxsOc/x0VUCefYMHBS4iMSIS+/lr4DpgO7AImOb+tGnAQm+FdMKM0emUlFfzz/X5TkcxxnhBbZ2LZ5fvp1/HVlyVnuB0nMviyRl4MrBKRLYA64B3VPV9YCYwTkRygHHu/aAxpEs8QzrH89yKA1TXupyOY4xpYm9vPUL+iQoeGJ3u11PGXswlC1xVD6hqP/dHL1X9nfv9ElUdq6oZ7m3QzQT1wJh0jpZWsmBTgdNRjDFNyOVSnlm2n8zkWK69ItnpOJfNnsS8iFEZCfTp0IpnPtlPbZ2dhRsTLD7YcYycwjK+M7obYWGBefYNVuAXJSJ8d0w6B0sqWLjZll0zJhi4XMqTS3PomhDj9ws2XIoV+CWM65nMFSlxPL1sn52FGxMEPtx5nN3HzjBjTDrhAXz2DVbglyQiPDg2ndzichZvPep0HGNMI6gqTy3NoXPb+mkzAp0VuAeu69mOHu1ieerjHOps8WNjAtZHuwrZefQ0M8ZkEOHny6V5IvB/Bj4QFiZ8b2wGB4rKWbzVxsKNCUSqypNL95IW34JJWYF/9g1W4B4b36sd3ZNb8peP99lZuDEB6OPdhWw/fJoZo9OD4uwbrMA9FhYmfHdMBvsKy3h3m42FGxNIPh/7To1vzq0DOjgdp8lYgTfAjX1SSE9qyZNLbSzcmEDy8e5CthSU8sA16TQLkrNvsAJvkPAw4fvX1p+Fv73FxsKNCQSqyuNL6se+vzKwo9NxmpQVeAPd2DuFHu1ieXJpjt0XbkwA+GDHcXYcOc33xmYE1dk3WIE3WFiY8INx3cktLmfBpsNOxzHGXITLpTyxZC9dE2KC5s6Tc1mBX4breibTp0Mrnvo4hxo7CzfGb72z7Sh7jp/hwWuD477vLwq+n5EPiAg/HNedQyfO8ka2zVRojD+qcyl//mgv3ZNbcnOAz3lyIVbgl+mazET6p7Xm6Y9zqKq1VXuM8TcLNx9mf1E5P7i2e0DPOHgxVuCXSUR4aFwmR0ormbfWVu0xxp/U1Ll4cmkOV6TEcX2vdk7H8Ror8EYYkd6WYV3jeXrZPsqrap2OY4xx++f6QxwsqeBH1wXv2TdYgTeKiPDw+B4Ul1Xz4qe5TscxxgBnq+t4amkOgzq1YUyPJKfjeJXHBS4i4SKySUQWu/fjRWSJiOS4t228F9N/DUhrw7ieyTy34gCnKqqdjmNMyJuzJo/CM1U8PL5HwK516amGnIE/COw6Z/8RYKmqZgBL3fsh6UfXZVJWVcvflu93OooxIa30bA1/+2Q/12QmMqRLvNNxvM6jAheRjsBNwPPnvD0RmON+PQeY1KTJAkhmu1huzerAS5/mcay00uk4xoSsWSv2U3q2hh9fn+l0FJ/w9Az8z8DDwLlPrSSr6lEA9/a8g00iMl1EskUku6ioqDFZ/doPxnXHpcpTH+c4HcWYkFR4ppLZq/K4uV97erVv5XQcn7hkgYvIBKBQVTdczgFUdZaqDlLVQYmJiZfzLQJCanwLpgxJ45/rD5FbXO50HGNCzl8/3kd1nYsfjuvudBSf8eQMfARwi4jkAf8AxojIq8BxEUkBcG8LvZYyQMwYk05URBj/88Eep6MYE1LyisuZuzafyYNT6ZIQ43Qcn7lkgavqT1W1o6p2Bu4APlbVu4BFwDT3p00DFnotZYBIio1m+qiuvLPtKJvyTzodx5iQ8acP9hAZEcb3r81wOopPNeY+8JnAOBHJAca590PeN0d2JaFlFL9/dzeqtuiDMd62Kf8k72w7yvRRXUmKjXY6jk81qMBV9RNVneB+XaKqY1U1w7094Z2IgSUmKoIfjMtgXd4JPtoV8qNKxniVqvL7d3eT0DKKb47s6nQcn7MnMb1g8qBUuibGMPO9XbbogzFetGTncdblneD712YQExXhdByfswL3gojwMB4Z34P9ReX8M/uQ03GMCUq1dS5mvr+brokxTB6c6nQcR1iBe8m4nskM7tyGJ5bk2ERXxnjBP7MPcaConJ+M7xF0S6V5KjR/1j4gIvzsxisoLqviWXvE3pgmdaayhieW7GVw5zZc1zPZ6TiOsQL3ov5pbZiY1Z5ZKw5w+NRZp+MYEzT+umw/xWXV/HJCz6CfsOpirMC97OHxPQD4w3u7HU5iTHDIL6lg9qpcbhvQgb4dWzsdx1FW4F7WoXVzpo/qyqItR9hoD/cY02gz399FeJjw8PU9nI7iOCtwH/jW1d1Iio3iscU77eEeYxphXe4J3t12jPuv7kq7VqH10M75WIH7QExUBD+6PpNN+adYtOWI03GMCUgul/LY4p20i6ufssJYgfvM7QM60qt9HH94bzdnq20Ve2Maav6mw2w7XMpPbsikRWToPbRzPlbgPhIWJvz65l4cKa20lXuMaaAzlTXMfG83/VJbM7FfB6fj+A0rcB8a0iWeW/q159nl+zl0osLpOMYEjL98vI+S8ioevaVXUK8y31BW4D720xt7EC7C/3tnp9NRjAkI+wrLmL0ql68NTKVfamun4/gVK3AfS2nVnBlj0vlgx3FW5gTvEnPGNAVV5bdv76B5ZDg/Hh8a61w2hBW4A+4b2YVObVvwm0U7qK612QqNuZAlO4+zMqeYH1zbnYSWUU7H8TtW4A6IigjnVxN6sr+onJfX5Dkdxxi/VFlTx2Pv7KR7ckumDu/kdBy/ZAXukDE9krgmM5E/f5TDsdJKp+MY43fqL/af5dc39wrZ2QYvxZNV6aNFZJ2IbBGRHSLyW/f78SKyRERy3Ns23o8bPESE39zci+o6l13QNOYL8orLeeaT/dzcrz0j0hOcjuO3PPlnrQoYo6r9gCxgvIgMAx4BlqpqBrDUvW8aoHNCDA9ck87irUftgqYxbqrKrxbtIDI8jF/edIXTcfyaJ6vSq6qWuXebuT8UmAjMcb8/B5jkjYDB7v6ru9IlIYZfLdxBZY09oWnMu9uOsWJvEQ9d152kOJvv5GI8GlgSkXAR2QwUAktUdS2QrKpHAdzbpAt87XQRyRaR7KIiO8v8ouhm4Tw6sRe5xeXMWnHA6TjGOKqsqpZHF++gV/s4pg6zC5eX4lGBq2qdqmYBHYEhItLb0wOo6ixVHaSqgxITEy8zZnAbmZHIhL4pPL1sHwdLyp2OY4xjnliyl8IzVfy/Sb2JsAuXl9SgXyFVPQV8AowHjotICoB7W9jU4ULJLyf0rB/zW7jDppw1IWnHkVJeWp3HlCFp9E+zeyI84cldKIki0tr9ujlwLbAbWARMc3/aNGChlzKGhOS4aH58fSYr9haxcLNNOWtCS22di0fe2kabFs14+Hp74tJTnpyBpwDLRGQrsJ76MfDFwExgnIjkAOPc+6YR7hrWiazU1jy6eCcnyqudjmOMz7y0Oo9th0v59c29aN0i0uk4AcOTu1C2qmp/Ve2rqr1V9VH3+yWqOlZVM9zbE96PG9zCw4SZX+nD6bM1dm+4CRmHTlTwvx/uZUyPJCb0TXE6TkCxqwR+pke7OL51dTfmbzxs94aboKeq/Pxf2wkTeGxS75BeYf5yWIH7oRlj0umaEMPPF2y31XtMUFu05Qgr9hbxo+sz6dC6udNxAo4VuB+KbhbOf9/Wh/wTFTy+ZI/TcYzxipKyKh59eydZqa25e3hnp+MEJCtwPzWsa1umDEnjhVW5bDh40uk4xjS5Xy/awenKGmZ+pQ/htsrOZbEC92M/u7EH7eKiefjNLfaYvQkq728/yuKtR3lwbAY92sU5HSdgWYH7sdjoZsz8Sl/2F5Xz549ynI5jTJM4WV7NL/61nd4d4rj/6m5OxwloVuB+blT3RO4YnMqsFfvZfOiU03GMabTfvL2D0rM1/On2fjbPdyPZr14A+NlNV9Q/qfmGDaWYwPbBjmMs3HyE747J4IoUGzppLCvwABAX3Yzf39aHnMIynvhor9NxjLksJ8qr+fmC7fRMiePb19jQSVOwAg8Q12QmMWVIKrNWHGBdrj30agKLqvKz+ds4fbaGxyfb0ElTsV/FAPKLm3qS2qYFP3x9M2cqa5yOY4zH5m88zPs7jvHQdd3trpMmZAUeQGKiInhicj+OnDrLY4ttrhQTGApOVvDrRTsY0iWe+0Z2dTpOULECDzADO8Xz7Wu68Xp2AR/uOOZ0HGMuyuVSHnp9CwD/+9V+9sBOE7MCD0APju1Or/Zx/HT+NorOVDkdx5gLemFVLmtzT/Crm3uSGt/C6ThBxwo8AEVGhPHE5CzKqmr50RtbcLlsBR/jf7YfLuWPH+zmup7JfHVgR6fjBCUr8ADVPTmWX0zoyfK9Rcz+NNfpOMb8h/KqWr43bxNtY6L4w1f62jSxXmIFHsDuGprGdT2T+cP7u9l+uNTpOMb8228W7SC3pJw/35FFmxhbYcdbrMADmIjwh6/0pW1MFN+dt4nyqlqnIxnDws2HeWNDATNGpzOsa1un4wQ1TxY1ThWRZSKyS0R2iMiD7vfjRWSJiOS4t7aMtAPaxETyxOQs8krK+fWiHU7HMSHu0IkKfrFgOwPSWvPg2Ayn4wQ9T87Aa4GHVPUKYBjwgIj0BB4BlqpqBrDUvW8cMLxbW2aMTufNDQW8taHA6TgmRFXV1jHjtY0g8OQd/Ymwpy29zpNFjY+q6kb36zPALqADMBGY4/60OcAkL2U0HnhwbAZDu8Tzi39tZ+/xM07HMSHov9/ZxZaCUv50ez+7ZdBHGvRPpIh0BvoDa4FkVT0K9SUPJF3ga6aLSLaIZBcV2SK93hIRHsZfpvQnJiqcb7+6wcbDjU+9veUIc9Yc5L6rujC+dzun44QMjwtcRFoCbwHfV9XTnn6dqs5S1UGqOigxMfFyMhoPJcVF89Qd/cktLudnC7ahaveHG+/bX1TGI29tZUBaa35yQw+n44QUjwpcRJpRX95zVXW+++3jIpLi/vEUoNA7EU1DXJmewA+u7c7CzUeYuzbf6TgmyJ2truM7r24kMiKMp78+wGYZ9DFP7kIR4AVgl6o+fs4PLQKmuV9PAxY2fTxzOR4Ync6o7ok8+vZONuXbgsjGO1SVny3Yxp7jZ3hichbtWzd3OlLI8eSfyxHAVGCMiGx2f9wIzATGiUgOMM69b/xAWJjw5OQskuKi+NarGyg8U+l0JBOEXvw0jwWbDvODa7tzTeZ5L4EZL/PkLpRVqiqq2ldVs9wf76pqiaqOVdUM99ZWGfAjbWIimTV1EKVna/jOqxuprnU5HckEkdX7i/ndu7u4rmcy3x2T7nSckGUDVkGsZ/s4/nh7P7IPnuTRxfaQj2kaBScrmPHaJjq3bcH/fq0fYTZFrGMinA5gvOuWfu3ZfriUWSsO0KdDKyYPTnM6kglglTV1fOvVDdTUuph19yBio5s5HSmk2Rl4CHj4+kxGZiTwi39tt/U0zWVzuZSH3tjCjiOneWJyFt0SWzodKeRZgYeAiPAwnp4ygNQ2Lbj/lWwOlpQ7HckEoD8vzeGdrUf5yfgeXNsz2ek4BivwkNGqRTNeuGcwLoVvvLSe0rO2KLLx3L82HeappTl8dWBH7h9l61r6CyvwENIlIYZn7xrIwZIKZry2kdo6uzPFXNqGgyd5+K2tDOkSz+9u7WOLM/gRK/AQM7xbW353a29W5hTzq0U77HF7c1H5JRXc/0o2Ka2iee6ugURGWGX4E7sLJQRNHpxGbnEFzy7fT4fWzXlgtN3Ha76spKyKaS+uo9alvDBtsK2s44eswEPUw9dncqz0LH/6YA9JsVF8dVCq05GMH6moruUbc7I5cuosc+8bSnqS3XHij6zAQ1RYmPDH2/tRVFbFI/O3kRgbZY9DGwBq61x897VNbCs4xd/uGsigzvFORzIXYANaISwyIoxn7xpIZnIs35m7ka0Fp5yOZBymqvxy4XaW7i7ktxN7c30vm9vbn1mBh7jY6Ga8dO9g4mMimTZ7HTm2mk/IUlVmvrebeesOMWN0OlOHdXI6krkEK3BDUlw0c+8bSrPwMO58fi35JRVORzIO+OuyfTy34gBTh3Xioeu6Ox3HeMAK3ADQqW0Mr943lOo6F19//jOOldoUtKHkxU9z+Z8P93Jb/w789pZedq93gLACN//WPTmWl78xhFMVNdz5/GcUl1U5Hcn4wOvZh/jt2zu5vlcyf7y9r80uGECswM1/6NuxNbPvGczhU2f5+t+txIPdmxsK+MlbWxmZkcBTU/oTYUuiBRT73TJfMqRLPLOnDSb/RIWVeBB7I/sQP35zCyO6JfD3uwcRFRHudCTTQJ6siTlbRApFZPs578WLyBIRyXFv23g3pvG1K9MTmH1PfYlPmfUZRWesxIPJ6+sP8fBbW7kqPYHnpw0iupmVdyDy5Az8JWD8F957BFiqqhnAUve+CTJXdkvgxXuGUHDyLFP+/hmFp+3CZjD4x7p8fjJ/KyMzEvn73VbegcyTNTFXAF9cBWAiMMf9eg4wqWljGX8xvFtbXrx3MEdOneX2Z9fYLYYBbtaK/TwyfxujMhKZNXWglXeAu9wx8GRVPQrg3l7wGWwRmS4i2SKSXVRUdJmHM04a1rUtr31zGKcra7j92dXsOWYP+wQaVeWP7+/mv9/dzYS+KXbmHSS8fhFTVWep6iBVHZSYmOjtwxkvyUptzRv3D0cEvvbcGjbmn3Q6kvFQnUv5xb+288wn+/n60DSevKO/TQsbJC73d/G4iKQAuLeFTRfJ+KuM5Fje/NaVtG7RjDv/vpaPdh53OpK5hMqaOr47byNz1+bz7Wu68btJvQm3+7yDxuUW+CJgmvv1NGBh08Qx/i41vgVvfGs4Gcktmf5KNi+vyXM6krmAkrIqpvz9M97bfoxf3HQFPxnfw56wDDKe3EY4D1gDZIpIgYj8FzATGCciOcA4974JEUmx0fxj+jDG9EjmVwt38NjindS5bGUff7K/qIxbn1nNrqOn+dudA7lvpK1jGYwuOR+4qk65wA+NbeIsJoC0iIzguakDeWzxTl5YlcuhExU8PjmLllE2xbzTVu8v5tuvbiQiTJj3zWH0T7PHNIKVXckwly08TPjNLb349c09+WjXcW7966fkFZc7HStkqSovrMpl6gvrSIyNYsF3Rlh5BzkrcNNo947owsvfGEpRWRW3PL2KT/bYNW1fq6yp46HXt/DY4p2M7ZHEvx4YQVrbFk7HMl5mBW6axFUZCbw94yo6tGnBvS+t5+mPc3DZuLhPHDpRwVefXcOCzYf54bjuPHvXQBvKChFW4KbJpMa3YP63r+Tmvu35nw/3Mu3FdTaHipe9u+0oNz61kryScp6/exDfG5th08GGECtw06SaR4bz5B1Z/P62PqzLPcENT65kVU6x07GCTmVNHT9fsI3vzN1It8SWvPu9kYy9ItnpWMbHrMBNkxMRpgxJY9GMq2jTohlTZ6/l9+/torKmzuloQWHnkdNM+uunzF2bz/2juvLGt4aTGm/j3aHICtx4TWa7WBbNuIo7Bqfy3PID3PyXVbbyfSPU1Ll4amkOtzy9iuKyal68dzA/vfEKmtkiDCHLfueNVzWPDOf3t/XlxXsHc7qyhlufWc3/friH6lqX09ECyp5jZ7jtmdU8vmQvN/ZJYckPRjE684JzyJkQIaq+u1Ng0KBBmp2d7bPjGf9SWlHDbxfvYP7Gw3RLjOGxSb25sluC07H8WkV1LX/5eB/PrzxAbHQzfjepNzf0SXE6lvExEdmgqoO+9L4VuPG1ZbsL+dWi7Rw6cZZJWe352U1XkBQb7XQsv6KqLNl5nN++vZPDp87ylQEd+dmNPWjbMsrpaMYBFypwu1nU+NzoHkks6XY1zyzbx7PLD7B0VyEzxqQz7crONkc19cMlv39vF5/sKSIzOZbX7x/OkC7xTscyfsjOwI2jcovLefTtHSzbU0SH1s156LruTMrqEJL3Mh8rreTxJXt4c0MBMVERfG9MBveM6GwXKY0NoRj/tnp/MTPf283WglKuSInjwbHpXNezXUgUeeGZSl5YmcucNXm4XHD38E48MDqdNjGRTkczfsIK3Pg9l0t5Z9tRHl+yl9zicjKSWvKd0d24uW97IoLwLPTwqbM8t3w//1x/iJo6FxOzOvDDcd3tnm7zJVbgJmDUuYv8mWX72H3sDKnxzZk6rBNfHZga8GelqsrG/FO8siaPxVuPIgK39e/It6/pRueEGKfjGT9lBW4CjsulLN1dyN9XHmBd7gmiIsK4uV977hyaRlZq64BaXaasqpbFW47w8pqD7Dx6mtioCG4f1JFvjuxK+9bNnY5n/JwVuAlou4+d5pU1B1mw6TAV1XV0btuCW7I6MDGrPd0SWzod77yqautYvqeIhVuO8NHO41TVuujRLpa7h3dmYlZ7YmzGQOMhK3ATFM5U1vDetmMs3HKY1ftLUIUe7WIZ3SOJ0ZlJDEhr7eh4eXFZFcv3FLFsTyEr9hZxurKW+JhIJvRNYWJWBwakBdb/HIx/8EqBi8h44EkgHHheVS+6NqYVuGlKx09X8vaWI3y06zjZeSepdSlx0REM6dKWgZ3aMCCtNX07tqZ5pHfuLVdVjpRWsuHgSTYePEn2wRNsP3wagISWUVyTmchNfVO4Kj3BbgU0jdLkBS4i4cBe6hc1LgDWA1NUdeeFvsYK3HjL6coaPs0pZtmeQtbnnSTXvbRbRJjQJSGG9KSWpCe1pFtiS1JaRZMYG0VSXDQxkeEXPSOucykl5VUUnq6iqKyK/JIK9hWWkVN4hn2FZRSXVQMQ3SyMvh1bMzI9gdE9kuiZEhcSt0Aa3/DGk5hDgH2qesB9gH8AE4ELFrgx3hIX3Ywb+qT8e56QkrIqNuWfYtOhk+w5VsbuY2f4YMcxvrhIUFREGM0jw4mKCCMqIpyIMKGq1kVVbR1VNS7Kq2u/9DWxURF0S2rJNZlJ9G4fx8BO8fRIibWzbONzjSnwDsChc/YLgKFf/CQRmQ5MB0hLS2vE4YzxXNuWUVzbM5lre/7fIgdVtXXkl1Rw/HQVhWcqKTpTRUl5NZU19WVdVVtHjUuJiggjull9qbeMiiApNorE2CgSY6Pp2KY5SbFRNo5t/EJjCvx8f4K/NB6jqrOAWVA/hNKI4xnTKFER4WQkx5KRHOt0FGOaRGP+z1cApJ6z3xE40rg4xhhjPNWYAl8PZIhIFxGJBO4AFjVNLGOMMZdy2UMoqlorIjOAD6i/jXC2qu5osmTGGGMuqlGPgqnqu8C7TZTFGGNMA9h9T8YYE6CswI0xJkBZgRtjTICyAjfGmADl09kIRaQIOHiZX54AFDdhnKbkr9n8NRf4bzZ/zQX+m81fc4H/Zmtork6qmvjFN31a4I0hItnnm8zFH/hrNn/NBf6bzV9zgf9m89dc4L/ZmiqXDaEYY0yAsgI3xpgAFUgFPsvpABfhr9n8NRf4bzZ/zQX+m81fc4H/ZmuSXAEzBm6MMeY/BdIZuDHGmHNYgRtjTIAKqAIXkcdEZKuIbBaRD0WkvdOZAETkTyKy251tgYi0djrT50TkqyKyQ0RcIuL47VQiMl5E9ojIPhF5xOk8nxOR2SJSKCLbnc5yLhFJFZFlIrLL/fv4oNOZPici0SKyTkS2uLP91ulM5xKRcBHZJCKLnc5yLhHJE5Ft7h5r1CLBAVXgwJ9Uta+qZgGLgV85nOdzS4DeqtqX+oWef+pwnnNtB24DVjgdxL0Q9l+BG4CewBQR6elsqn97CRjvdIjzqAUeUtUrgGHAA370a1YFjFHVfkAWMF5Ehjkb6T88COxyOsQFjFbVrMbeCx5QBa6qp8/ZjeE8S7g5QVU/VNVa9+5n1K9O5BdUdZeq7nE6h9u/F8JW1Wrg84WwHaeqK4ATTuf4IlU9qqob3a/PUF9IHZxNVU/rlbl3m7k//OLvpIh0BG4Cnnc6izcFVIEDiMjvROQQcCf+cwZ+rm8A7zkdwk+dbyFsvyijQCAinYH+wFqHo/ybe5hiM1AILFFVf8n2Z+BhwOVwjvNR4EMR2eBe9P2y+V2Bi8hHIrL9PB8TAVT156qaCswFZvhLLvfn/Jz6//LO9VUuT7P5CY8WwjZfJiItgbeA73/hf6KOUtU695BmR2CIiPR2OBIiMgEoVNUNTme5gBGqOoD6ocQHRGTU5X6jRq3I4w2qeq2Hn/oa8A7way/G+bdL5RKRacAEYKz6+Ob6BvyaOc0Wwr4MItKM+vKeq6rznc5zPqp6SkQ+of46gtMXgkcAt4jIjUA0ECcir6rqXQ7nAkBVj7i3hSKygPqhxcu6RuV3Z+AXIyIZ5+zeAux2Ksu5RGQ88BPgFlWtcDqPH7OFsBtIRAR4Adilqo87nedcIpL4+R1XItIcuBY/+Dupqj9V1Y6q2pn6P2Mf+0t5i0iMiMR+/hq4jkb8gxdQBQ7MdA8NbKX+J+4vt1Q9DcQCS9y3Bj3rdKDPicitIlIADAfeEZEPnMrivtD7+ULYu4DX/WUhbBGZB6wBMkWkQET+y+lMbiOAqcAY95+tze4zS3+QAixz/31cT/0YuF/dsueHkoFVIrIFWAe8o6rvX+43s0fpjTEmQAXaGbgxxhg3K3BjjAlQVuDGGBOgrMCNMSZAWYEbY0yAsgI3xpgAZQVujDEB6v8DbenujjPm4bAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=[1,2,3]\n",
    "y=[1,2,3]\n",
    "w=tf.placeholder(tf.float32)\n",
    "hypothesis = w*x\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-y))\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "w_val=[]\n",
    "cost_val=[]\n",
    "for i in range(-30,50):\n",
    "    feed_w = i*0.1\n",
    "    curr_cost, curr_w = sess.run([cost,w], feed_dict = {w: feed_w})\n",
    "    w_val.append(curr_w)\n",
    "    cost_val.append(curr_cost)\n",
    "    \n",
    "#show the cost function\n",
    "plt.plot(w_val, cost_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3107e5de",
   "metadata": {},
   "source": [
    "### cost함수 미분하기\n",
    "    위의 cost function에서 gradient descent를 활용하여 미분하기\n",
    "    cost(w)를 미분했을 때 양/음 값이 나오면 w값을 -/+조절하는 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bffc0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimize: Gradient Descent using derivative(미분):\n",
    "#w -= Learning_rate * derivative\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((w*x-y)*x)\n",
    "descent = w - learning_rate * gradient\n",
    "update = w.assign(descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7322a276",
   "metadata": {},
   "source": [
    "## full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f1e2a358",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-77-e016a020bed2>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-77-e016a020bed2>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    이 부분이\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x_data=[1,2,3]\n",
    "y_data=[1,2,3]\n",
    "\n",
    "w=tf.Variable(tf.random_normal([1]), name = 'weight')\n",
    "x=tf.placeholder(tf.float32, shape=[None])\n",
    "y=tf.placeholder(tf.float32, shape=[None])\n",
    "hy=w*x\n",
    "cost = tf.reduce_mean(tf.square(hy-y))\n",
    "\n",
    "#이 부분이\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "#train = optimizer.minimize(cost)\n",
    "#로 대체할 수 있는 것\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((w*x-y)*x)\n",
    "descent = w - learning_rate * gradient\n",
    "update = w.assign(descent)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={x:x_data,y:y_data})\n",
    "    print(step, sess.run(cost,feed_dict={x:x_data,y:y_data}), sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfd26a2",
   "metadata": {},
   "source": [
    "# 04-1) multi-variable linear regression 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc92809e",
   "metadata": {},
   "source": [
    "### Matrix (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e70abb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 6857.9805 \n",
      "prediction:\n",
      " [230.88612 268.25198 268.94876 295.0552  200.41382] \n",
      "\n",
      "1000 cost: 19.456238 \n",
      "prediction:\n",
      " [155.80194 181.36035 181.5949  200.04129 134.87935] \n",
      "\n",
      "2000 cost: 12.462451 \n",
      "prediction:\n",
      " [154.45819 182.28967 181.19348 199.67053 136.16678] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#여기부터\n",
    "x1_data = [73,93, 89, 96, 73]\n",
    "x2_data = [80, 88, 91, 98, 66]\n",
    "x3_data = [75, 93, 90, 100, 70]\n",
    "y_data = [152, 185, 180, 196, 142]\n",
    "\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "#여기까지 매트리스로 구현 가능\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1*w1 + x2*w2 + x3*w3 +b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                        feed_dict={x1: x1_data, x2:x2_data, x3: x3_data, y: y_data})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, \"cost:\", cost_val, \"\\nprediction:\\n\", hy_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e316d",
   "metadata": {},
   "source": [
    "### Matrix (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d4e91314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 12.730005 \n",
      "prediction:\n",
      " [[151.74472]\n",
      " [189.52249]\n",
      " [183.12512]\n",
      " [198.33475]\n",
      " [147.28342]] \n",
      "\n",
      "1000 cost: 2.383389 \n",
      "prediction:\n",
      " [[149.75215]\n",
      " [185.91283]\n",
      " [180.19905]\n",
      " [195.09326]\n",
      " [144.27356]] \n",
      "\n",
      "2000 cost: 1.4940068 \n",
      "prediction:\n",
      " [[150.24074]\n",
      " [185.57631]\n",
      " [180.3467 ]\n",
      " [195.21582]\n",
      " [143.81873]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[73,80,75],[93,88,93],[89,91,90],[96,98,100],[73,66,70]]\n",
    "y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None,3])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "#w는 normal([들어오는 값,나가는 값])\n",
    "#b는 nomal([나가는 값])\n",
    "w = tf.Variable(tf.random_normal([3,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(x,w)+b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                        feed_dict={x: x_data, y: y_data})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, \"cost:\", cost_val, \"\\nprediction:\\n\", hy_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6f5bc",
   "metadata": {},
   "source": [
    "# 04-2) 파일에서 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49a567fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# Make sure the shape and data are OK\n",
    "#print(x_data.shape, \"\\n\", x_data, len(x_data))\n",
    "#print(y_data.shape, \"\\n\", y_data, len(y_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c38358a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Score will be [[185.00087]]\n",
      "Your Score will be [[172.86266]\n",
      " [178.56493]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None,3])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "#w는 normal([들어오는 값,나가는 값])\n",
    "#b는 nomal([나가는 값])\n",
    "w = tf.Variable(tf.random_normal([3,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(x,w)+b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                        feed_dict={x: x_data, y: y_data})\n",
    "    #if step % 1000 == 0:\n",
    "    #    print(step, \"cost:\", cost_val, \"\\nprediction:\\n\", hy_val, \"\\n\")\n",
    "\n",
    "print(\"Your Score will be\", sess.run(hypothesis, feed_dict={x: [[100,70,101]]}))\n",
    "print(\"Your Score will be\", sess.run(hypothesis, feed_dict={x: [[60,70,110],[90,100,80]]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727a3783",
   "metadata": {},
   "source": [
    "### Queue Runners 이용 - 이해 부족"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a4c7b",
   "metadata": {},
   "source": [
    "    파일의 양, 크기가 너무 클 경우 용량이 부족해진다.\n",
    "    tensorflow의 queue runner를 이용하여 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033d36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-563d13f86f69>:3: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-1-563d13f86f69>:4: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-1-563d13f86f69>:11: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\jiho kang\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-563d13f86f69>:29: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    ['data-01-test-scroe.csv'], shuffle=False, name='filename_queue')\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.],[0.],[0.],[0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[0:-1], xy[-1]], batch_size=10)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None,3])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "#w는 normal([들어오는 값,나가는 값])\n",
    "#b는 nomal([나가는 값])\n",
    "w = tf.Variable(tf.random_normal([3,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(x,w)+b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis-y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                        feed_dict={x: x_data, y: y_data})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, \"cost:\", cost_val, \"\\nprediction:\\n\", hy_val, \"\\n\")\n",
    "        \n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1db6a8",
   "metadata": {},
   "source": [
    "# 05) Logistic Classification 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a74518d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6067502\n",
      "1000 0.48719576\n",
      "2000 0.40847698\n",
      "3000 0.34736288\n",
      "4000 0.299703\n",
      "5000 0.26227972\n",
      "6000 0.2325253\n",
      "7000 0.20851499\n",
      "8000 0.18884479\n",
      "9000 0.17249645\n",
      "10000 0.1587277\n",
      "\n",
      "Hypothesis: [[0.03471711]\n",
      " [0.16390936]\n",
      " [0.32336465]\n",
      " [0.77305526]\n",
      " [0.9342066 ]\n",
      " [0.97838426]] \n",
      "correct(y): [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1,2],[2,3],[3,1],[4,3],[5,3],[6,2]]\n",
    "y_data = [[0],[0],[0],[1],[1],[1]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None,2])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "#w는 normal([들어오는 값,나가는 값])\n",
    "#b는 nomal([나가는 값])\n",
    "w = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hypothesis)+(1-y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "#if문 같은 것.\n",
    "# true if hypothesis>0.5 and return(TorF) in float. T=1, F=0\n",
    "predicted = tf.cast(hypothesis>0.5, dtype = tf.float32)\n",
    "\n",
    "#predict값과 y의 값이 같으면 true, false를 float으로 반환하여 평균을 냄\n",
    "#값이 높을수록 정확도가 높은 것\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y),dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={x: x_data, y:y_data})\n",
    "        if step % 1000 == 0:\n",
    "            print(step,cost_val)\n",
    "            \n",
    "    h,c,a = sess.run([hypothesis,predicted,accuracy], feed_dict={x: x_data, y:y_data})\n",
    "    print(\"\\nHypothesis:\",h,\"\\ncorrect(y):\",c,\"\\nAccuracy:\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc729a8",
   "metadata": {},
   "source": [
    "### Classifying diabetes (실제 데이터로 당뇨병 예측하기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab7cc8e6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.78851503\n",
      "1000 0.19812554\n",
      "2000 0.13121735\n",
      "3000 0.09905819\n",
      "4000 0.079812214\n",
      "5000 0.06692143\n",
      "6000 0.057655923\n",
      "7000 0.05066346\n",
      "8000 0.04519385\n",
      "9000 0.040795926\n",
      "10000 0.037181523\n",
      "\n",
      "Hypothesis: [[0.07710411]\n",
      " [0.9445081 ]\n",
      " [0.01855678]\n",
      " [0.9809976 ]\n",
      " [0.01058839]] \n",
      "correct(y): [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('data-03-diabetes.csv', delimiter = ',', dtype=np.float32)\n",
    "x_data=xy[:,0:-1]#여기 한번 수정해보기\n",
    "y_data=xy[:,[-1]]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None,8])\n",
    "y = tf.placeholder(tf.float32, shape=[None,1])\n",
    "\n",
    "#w는 normal([들어오는 값,나가는 값])\n",
    "#b는 nomal([나가는 값])\n",
    "w = tf.Variable(tf.random_normal([8,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "\n",
    "cost = -tf.reduce_mean(y*tf.log(hypothesis)+(1-y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "#if문 같은 것.\n",
    "# true if hypothesis>0.5 and return(TorF) in float. T=1, F=0\n",
    "predicted = tf.cast(hypothesis>0.5, dtype = tf.float32)\n",
    "\n",
    "#predict값과 y의 값이 같으면 true, false를 float으로 반환하여 평균을 냄\n",
    "#값이 높을수록 정확도가 높은 것\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y),dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={x: x_data, y:y_data})\n",
    "        if step % 1000 == 0:\n",
    "            print(step,cost_val)\n",
    "            \n",
    "    h,c,a = sess.run([hypothesis,predicted,accuracy], feed_dict={x: x_data, y:y_data})\n",
    "    print(\"\\nHypothesis:\",h,\"\\ncorrect(y):\",c,\"\\nAccuracy:\",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d3131",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# 06-1) Softmax Classification 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02bbca9",
   "metadata": {},
   "source": [
    "### 배운 이론을 식으로 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1563c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#먼저 XW=Y를 만들어주기 위해\n",
    "Z = tf.matmul(x,w)+b\n",
    "\n",
    "#hypothesis에 기존에는 sigmoid함수를 사용했다면\n",
    "hypothesis = tf.nn.softmax(Z)\n",
    "\n",
    "#cost function으로 나타내기\n",
    "cost= tf.reduce_mean(-tf.reduce_sum(y*tf.log(hypothesis),axis=1))\n",
    "\n",
    "#cost function 최소화하기\n",
    "optimizer = tf.train.GradienDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "#arg_max\n",
    "#훈련시킨 다음, 데이터를 넣어서 hypothesis로 나온 값을 one-hot codind된 수로 출력하기\n",
    "a = sess.run(hypothesis, feed_dict={x:[넣을 데이터 값]})\n",
    "print(a, sess.run(tf.arg_max(a,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85df26",
   "metadata": {},
   "source": [
    "### 실제 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9249b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0332339e-02 9.8965961e-01 8.0269629e-06]\n",
      " [8.0925775e-01 1.7901002e-01 1.1732193e-02]\n",
      " [1.4909554e-08 3.5893073e-04 9.9964106e-01]] [1 0 2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = [[1,2,1,1,],[2,1,3,2,],[3,1,3,4,],[4,1,5,5,],[1,7,5,5],[1,2,5,6],[1,6,6,6,],[1,7,7,7,]]\n",
    "#one-hot encoding\n",
    "y_data = [[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]]\n",
    "\n",
    "x=tf.placeholder(\"float\",[None, 4])\n",
    "y=tf.placeholder(\"float\",[None, 3])\n",
    "nb_classes = 3\n",
    "\n",
    "#w는 normal([들어오는 값,나가는 값])\n",
    "#b는 nomal([나가는 값])\n",
    "w = tf.Variable(tf.random_normal([4, nb_classes]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(x,w)+b)\n",
    "\n",
    "#cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2000):\n",
    "        sess.run(optimizer, feed_dict={x:x_data, y:y_data})\n",
    "    \n",
    "    a = sess.run(hypothesis, feed_dict={x: [[1,11,7,9],[1,3,4,3],[1,1,0,1]]})\n",
    "    print(a, sess.run(tf.math.argmax(a,1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c4e65",
   "metadata": {},
   "source": [
    "# 06-2) Fancy한 Softmax Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146aa790",
   "metadata": {},
   "source": [
    "cross_entropy, one_hot, reshape 함수를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d8978",
   "metadata": {},
   "source": [
    "### tf.nn.softmax_cross_entropy_with_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675be7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_x = tf.matual(x,w)+b\n",
    "hypothesis = tf.nn.softmax(logits_x)\n",
    "\n",
    "#1 기존\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(hpyothesis), axis=1))\n",
    "\n",
    "#2 함수 사용\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits = logits_x,\n",
    "                                                labels = y)\n",
    "cost = tf.reduce_mean(cost_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56908c96",
   "metadata": {},
   "source": [
    "### tf.one_hot() & tf.reshape()\n",
    "one_hot으로 인해 실제 데이터에 한 차원이 더 생김. reshape으로 되돌려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 7 #y값의 범위. 해당예시) 0~6\n",
    "y = tf.placholder(tf.int32,[None,1]) #shape=(?,1)\n",
    "y_one_hot = tf.one_hot(y,nb_classes) #shape=(?,1,7)\n",
    "y_one_hot = tf.reshape(Y_one_hot, [-1,nb_classes]) #shape=(?,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20350732",
   "metadata": {},
   "source": [
    "### 실제 데이터로 classification\n",
    "TF버전이 바뀌면서 돌아가지 않음\n",
    "\n",
    "TF2 버전 코드\n",
    "\n",
    "https://github.com/hunkim/DeepLearningZeroToAll/tree/master/tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bcd5c10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-106-15710b52eec7>:23: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert value <tf.Tensor 'ArgMax_4:0' shape=(?,) dtype=int64> to a TensorFlow DType.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-15710b52eec7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_one_hot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcast\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m   \"\"\"\n\u001b[1;32m--> 671\u001b[1;33m   \u001b[0mbase_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m   if isinstance(x,\n\u001b[0;32m    673\u001b[0m                 (ops.Tensor, _resource_variable_type)) and base_type == x.dtype:\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[1;34m(type_value)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m   raise TypeError(\"Cannot convert value %r to a TensorFlow DType.\" %\n\u001b[1;32m--> 717\u001b[1;33m                   (type_value,))\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert value <tf.Tensor 'ArgMax_4:0' shape=(?,) dtype=int64> to a TensorFlow DType."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#predicting animal type based on various features\n",
    "xy = np.loadtxt('data-04-zoo.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:,:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "nb_classes = 7\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None,16])\n",
    "y = tf.placeholder(tf.int32, [None,1])\n",
    "\n",
    "y_one_hot = tf.one_hot(y,nb_classes)\n",
    "y_one_hot = tf.reshape(y_one_hot, [-1, nb_classes])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([16,nb_classes]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name = 'weight')\n",
    "\n",
    "logits = tf.matmul(x,w)+b\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.argmax(hypothesis,1)\n",
    "answer = tf.equal(prediction, tf.argmax(y_one_hot,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(answer,prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict={x:x_data, y:y_data})\n",
    "        if step %100 == 0:\n",
    "            lass, acc = sess.run([cost, accuracy], feed_dict={x:x_data, y:y_data})\n",
    "            print(\"step:{:5}\\tLoss: {:.3f}\\t.Acc: {:.2%}\".format(step,loss,acc))\n",
    "    \n",
    "    predict = sess.run(prediction, feed_data={x:x_data})\n",
    "    \n",
    "    for p,y in zip(predict,y_data.flatten()):\n",
    "        print(\"[{}] Prediction: {} Real Y: {}\".format(p==int(y),p,int(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa953f4",
   "metadata": {},
   "source": [
    "# 07-1) training/test dataset, learning rate, normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71eace7",
   "metadata": {},
   "source": [
    "### Min_max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def min_max_scaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "\n",
    "xy = np.array(\n",
    "    [\n",
    "        [828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "        [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "        [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "        [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "        [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "        [819, 823, 1198100, 816, 820.450012],\n",
    "        [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "        [809.51001, 816.659973, 1398100, 804.539978, 809.559998],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# very important. It does not work without it.\n",
    "xy = min_max_scaler(xy)\n",
    "print(xy)\n",
    "\n",
    "'''\n",
    "[[0.99999999 0.99999999 0.         1.         1.        ]\n",
    " [0.70548491 0.70439552 1.         0.71881782 0.83755791]\n",
    " [0.54412549 0.50274824 0.57608696 0.606468   0.6606331 ]\n",
    " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
    " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
    " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
    " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
    " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
    "'''\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=1, input_dim=4))\n",
    "tf.model.add(tf.keras.layers.Activation('linear'))\n",
    "tf.model.compile(loss='mse', optimizer=tf.keras.optimizers.SGD(lr=1e-5))\n",
    "tf.model.summary()\n",
    "\n",
    "history = tf.model.fit(x_data, y_data, epochs=1000)\n",
    "\n",
    "predictions = tf.model.predict(x_data)\n",
    "score = tf.model.evaluate(x_data, y_data)\n",
    "\n",
    "print('Prediction: \\n', predictions)\n",
    "print('Cost: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50137b6a",
   "metadata": {},
   "source": [
    "### Learning rate and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2802aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 7 Learning rate and Evaluation\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "# try different learning_rate\n",
    "# learning_rate = 65535  # ? it works too hahaha\n",
    "learning_rate = 0.1\n",
    "# learning_rate = 1e-10  # small learning rate won't work either\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=3, input_dim=3, activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.SGD(lr=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "tf.model.fit(x_data, y_data, epochs=1000)\n",
    "\n",
    "# predict\n",
    "print(\"Prediction: \", tf.model.predict_classes(x_test))\n",
    "\n",
    "# Calculate the accuracy\n",
    "print(\"Accuracy: \", tf.model.evaluate(x_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6670e6e6",
   "metadata": {},
   "source": [
    "# 08) Tensor Manipluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e692365d",
   "metadata": {},
   "source": [
    "#### simple ID array and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b0120dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 1., 2., 3., 4., 5., 6.])\n",
      "1\n",
      "(7,)\n",
      "0.0 1.0 2.0\n",
      "[0. 1. 2. 3. 4. 5.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "t = np.array([0.,1.,2.,3.,4.,5.,6.])\n",
    "pp.pprint(t)\n",
    "print(t.ndim) #rank #1차원\n",
    "print(t.shape) #shape #모양, 몇 개가 있는지\n",
    "print(t[0], t[1], t[2])\n",
    "print(t[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "178c3b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 1.,  2.,  3.],\n",
      "       [ 4.,  5.,  6.],\n",
      "       [ 7.,  8.,  9.],\n",
      "       [10., 11., 12.]])\n",
      "2\n",
      "(4, 3)\n",
      "[1. 2. 3.] [4. 5. 6.] [7. 8. 9.]\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "t = np.array([[1.,2.,3.],[4.,5.,6.],[7.,8.,9.],[10.,11.,12.]])\n",
    "pp.pprint(t)\n",
    "print(t.ndim) #rank:2차원, 첫 '[' 갯수\n",
    "print(t.shape) #shape: 뒤에서부터 가장 안쪽 차원에 있는 원소의 갯수\n",
    "print(t[0], t[1], t[2])\n",
    "print(t[0:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a95cf",
   "metadata": {},
   "source": [
    "#### Shape, Rank, Axis\n",
    "    rank: 2 -> shape:[?,?]\n",
    "    rank: 3 -> shape:[?,?,?]\n",
    "    Axis는 매트리스를 표현했을 때, y축을 의미. 왼쪽부터 0\n",
    "    위에서는 axis = 0은 [1,4,7,10]부분.\n",
    "    axis = 1은 [1,2,3], [4,5,6], [7,8,9], [10,11,12]를 의미.\n",
    "    아직 axis개념 부족"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23658a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess=tf.Session()\n",
    "\n",
    "t = tf.constant([1,2,3,4])\n",
    "tf.shape(t).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75784f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1,2],[3,4]])\n",
    "tf.shape(t).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6ca5e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[[[1,2,3,4],[5,6,7,8,],[9,10,11,12]],\n",
    "                  [[13,14,15,16],[17,18,19,20],[21,22,23,24]]]])\n",
    "tf.shape(t).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2958a828",
   "metadata": {},
   "source": [
    "#### Matmul VS multiply\n",
    "matmul은 매트릭스의 곱이고, 단순 multiply는 산수곱이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdc84e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix1 shape:  (2, 2)\n",
      "matrix2 shape:  (2, 1)\n",
      "[[ 5]\n",
      " [11]]\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess=tf.Session()\n",
    "\n",
    "matrix1 = tf.constant([[1,2],[3,4]])\n",
    "matrix2 = tf.constant([[1],[2]])\n",
    "print(\"matrix1 shape: \", matrix1.shape)\n",
    "print(\"matrix2 shape: \", matrix2.shape)\n",
    "print(tf.matmul(matrix1,matrix2).eval(session=sess))\n",
    "print(tf.matmul(matrix1,matrix2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dce2b2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [6, 8]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(matrix1*matrix2).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12898d6",
   "metadata": {},
   "source": [
    "#### Reduce mean / Reduce_sum\n",
    "int가 아닌 float으로 계산해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76dd23a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess=tf.Session()\n",
    "\n",
    "print(tf.reduce_mean([1,2], axis = 0).eval(session=sess))\n",
    "print(tf.reduce_sum([1,2], axis = 0).eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0dec8f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "x = [[1.,2.],[3.,4.]]\n",
    "\n",
    "print(tf.reduce_mean(x).eval(session=sess))\n",
    "print(tf.reduce_sum(x).eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "81a6001b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3.]\n",
      "[4. 6.]\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_mean(x, axis = 0).eval(session=sess))\n",
    "print(tf.reduce_sum(x, axis = 0).eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7c6f30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 3.5]\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_mean(x, axis = 1).eval(session=sess))\n",
    "print(tf.reduce_sum(x, axis = 1).eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42bbd1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 3.5]\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_mean(x, axis = -1).eval(session=sess))\n",
    "print(tf.reduce_sum(x, axis = -1).eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db41ff6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.reduce_sum(x, axis = -1)).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7c36fa",
   "metadata": {},
   "source": [
    "#### Argmax\n",
    "가장 큰 값의 위치 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "047fe59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [[0,1,2],\n",
    "     [2,1,0]]\n",
    "tf.argmax(x, axis = 0).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18a4f0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(x, axis = 1).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02293350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(x, axis = -1).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0c882",
   "metadata": {},
   "source": [
    "#### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea4c86ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([[[0,1,2],\n",
    "               [3,4,5]],\n",
    "              \n",
    "              [[6,7,8],\n",
    "               [9,10,11]]])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a43ca9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(t, shape=[-1,3]).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1113a842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2]],\n",
       "\n",
       "       [[ 3,  4,  5]],\n",
       "\n",
       "       [[ 6,  7,  8]],\n",
       "\n",
       "       [[ 9, 10, 11]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(t, shape=[-1,1,3]).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575edeb4",
   "metadata": {},
   "source": [
    "Reshape (squeeze, expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "25146bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess=tf.Session()\n",
    "\n",
    "tf.squeeze([[0],[1],[2]]).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "54c42f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims([0,1,2],1).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ce70b",
   "metadata": {},
   "source": [
    "#### one hot\n",
    "one_hot을 사용하면 rank가 하나 더 추가되므로, reshape으로 바꾸어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e2cfb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess=tf.Session()\n",
    "\n",
    "t = tf.one_hot([[0],[1],[2],[1],[3]], depth = 4).eval(session=sess)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c960dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(t, shape=[-1,4]).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4146a",
   "metadata": {},
   "source": [
    "#### Casting\n",
    "정수로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f475b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast([1.8,2.2,3.3,4.9], tf.int32).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8a871e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast([True, False, 1 == 1, 0 == 1], tf.int32).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133cf893",
   "metadata": {},
   "source": [
    "#### Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3317c14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 7],\n",
       "       [2, 5, 8],\n",
       "       [3, 6, 9]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,4,7]\n",
    "y = [2,5,8]\n",
    "z = [3,6,9]\n",
    "\n",
    "tf.stack([x,y,z]).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0d119cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 7],\n",
       "       [2, 5, 8],\n",
       "       [3, 6, 9]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([x,y,z], axis = 0).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9b67fcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([x,y,z], axis = 1).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a898d491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([x,y,z], axis = -1).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3044af0f",
   "metadata": {},
   "source": [
    "#### Ones and Zeros like\n",
    "똑같은 모양으로 1 or 0으로 채워진 tens를 만들고 싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6ce7aa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =[[0,1,2],\n",
    "    [2,1,0]]\n",
    "tf.ones_like(x).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6be8270b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros_like(x).eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e38b513",
   "metadata": {},
   "source": [
    "#### Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7f35bd0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "2 5\n",
      "3 6\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip([1,2,3],[4,5,6]):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e2ac0cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4 7\n",
      "2 5 8\n",
      "3 6 9\n"
     ]
    }
   ],
   "source": [
    "for x,y,z in zip([1,2,3],[4,5,6],[7,8,9]):\n",
    "    print(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf50db",
   "metadata": {},
   "source": [
    "# 09-1) Neural Net for XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566a9c1d",
   "metadata": {},
   "source": [
    "아래처럼 구하면 결과가 나오지 않음. 그 이유는 레이어가 하나라서. 그러므로 레이어를 더 추가해줘야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6f85e01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.80094564 [[0.50466466]\n",
      " [1.559028  ]]\n",
      "2000 0.69314706 [[0.00046584]\n",
      " [0.00046973]]\n",
      "4000 0.6931472 [[1.6850956e-07]\n",
      " [1.6900614e-07]]\n",
      "6000 0.6931472 [[1.3274664e-07]\n",
      " [1.3324322e-07]]\n",
      "8000 0.6931472 [[1.3274664e-07]\n",
      " [1.3324322e-07]]\n",
      "10000 0.6931472 [[1.3274664e-07]\n",
      " [1.3324322e-07]]\n",
      "\n",
      "Hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "#XOR with logistic regression\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = np.array([[0,0],[0,1],[1,0],[1,1]], dtype = np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype = np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "w = tf.Variable(tf.random_normal([2,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "#hypothesis using sigmoid\n",
    "hypothesis = tf.sigmoid(tf.matmul(x,w)+b)\n",
    "\n",
    "#cost/loss function\n",
    "cost = -tf.reduce_mean(y*tf.log(hypothesis)+(1-y)*tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "                                                                     \n",
    "#Accuracy computation\n",
    "#True if hypothesis >0.5 else False\n",
    "predicted = tf.cast(hypothesis>0.5,dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype = tf.float32))\n",
    "\n",
    "#Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #initialize tensorflow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x: x_data, y:y_data})\n",
    "        if step % 2000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={x: x_data, y:y_data}), sess.run(w))\n",
    "            \n",
    "    h,c,a = sess.run([hypothesis, predicted, accuracy], feed_dict={x: x_data, y:y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e12efd",
   "metadata": {},
   "source": [
    "레이어 추가해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ed71a1f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7064974 [array([[-0.8171747 ,  0.57096416],\n",
      "       [ 0.08401517, -1.1195091 ]], dtype=float32), array([[-0.27196887],\n",
      "       [ 1.2272326 ]], dtype=float32)]\n",
      "2000 0.67902285 [array([[-0.9415418 , -0.98512304],\n",
      "       [-0.43661335, -1.017343  ]], dtype=float32), array([[-0.5640654],\n",
      "       [ 1.3629353]], dtype=float32)]\n",
      "4000 0.18275967 [array([[-4.1249113, -3.3094745],\n",
      "       [-4.1097035, -3.3031285]], dtype=float32), array([[-5.7477336],\n",
      "       [ 4.9115906]], dtype=float32)]\n",
      "6000 0.04809258 [array([[-5.3413525, -4.4068675],\n",
      "       [-5.3367634, -4.4055114]], dtype=float32), array([[-8.360147],\n",
      "       [ 7.608292]], dtype=float32)]\n",
      "8000 0.025550209 [array([[-5.7786655, -4.834289 ],\n",
      "       [-5.7757406, -4.833503 ]], dtype=float32), array([[-9.505008],\n",
      "       [ 8.820984]], dtype=float32)]\n",
      "10000 0.017100647 [array([[-6.0319076, -5.085617 ],\n",
      "       [-6.029661 , -5.085038 ]], dtype=float32), array([[-10.227912],\n",
      "       [  9.581648]], dtype=float32)]\n",
      "\n",
      "Hypothesis:  [[0.01403944]\n",
      " [0.9846677 ]\n",
      " [0.984671  ]\n",
      " [0.02309409]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#XOR with logistic regression\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "x_data = np.array([[0,0],[0,1],[1,0],[1,1]], dtype = np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype = np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2,2]), name = 'weight1')\n",
    "# x를 두개로 나누었으니 input:2, output: 임의로 2라 설정\n",
    "# Wide NN for XOR: 만약 output을 10까지 넓히면 더 정확한 값이 나온다.\n",
    "# Deep NN for XOR: w1,2뿐만 아니라 wN까지 깊게 연결한다면 더 정확한 값이 나온다.\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([2]), name = 'bias1')\n",
    "#output이 2이므로 여기도 2\n",
    "\n",
    "layer1 = tf.sigmoid(tf.matmul(x,w1)+b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([2,1]), name = 'weight2') #layer1의 값이 2개이니 input:2, output: y이므로 1\n",
    "b2 = tf.Variable(tf.random_normal([1]), name = 'bias2')\n",
    "\n",
    "#hypothesis using sigmoid\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1,w2)+b2)\n",
    "\n",
    "#cost/loss function\n",
    "cost = -tf.reduce_mean(y*tf.log(hypothesis)+(1-y)*tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "                                                                     \n",
    "#Accuracy computation\n",
    "#True if hypothesis >0.5 else False\n",
    "predicted = tf.cast(hypothesis>0.5,dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y), dtype = tf.float32))\n",
    "\n",
    "#Launch graph\n",
    "with tf.Session() as sess:\n",
    "    #initialize tensorflow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict={x: x_data, y:y_data})\n",
    "        if step % 2000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={x: x_data, y:y_data}), sess.run([w1, w2]))\n",
    "            \n",
    "    h,c,a = sess.run([hypothesis, predicted, accuracy], feed_dict={x: x_data, y:y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2217f8",
   "metadata": {},
   "source": [
    "# 09-2) Tensorboard (Neural Net for XOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9298a3",
   "metadata": {},
   "source": [
    "TensorBoard: TF logging/debugging tool\n",
    "\n",
    "- visualize TF graph\n",
    "- plot quantitative metrics\n",
    "- show additional data\n",
    "\n",
    "#### 5 Steps of using TensorBoard\n",
    "\n",
    "1) From TF graph, decide which tensors you want to log\n",
    "    \n",
    "   - w2_hist = tf.summary.histogram(\"weights2\",w2)\n",
    "   - cost_summ = tf.summary.scalar(\"cost\",cost)\n",
    "\n",
    "2) Merge all summaries\n",
    "   \n",
    "   - summary = tf.summary.merge_all()\n",
    "\n",
    "3) Create writer and add graph\n",
    "    \n",
    "   - writer = tf.summary.FileWriter('./logs') <=파일의 위치\n",
    "\n",
    "4) Run summary merge and add_summary\n",
    "    \n",
    "   - s, _ = sess.run([summary, optimizer], feed_dict=feed_dict)\n",
    "   - writer.add_summary(s, global_step=global_step)\n",
    "\n",
    "5) Launch TensorBoard\n",
    "    \n",
    "   - tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede75b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
